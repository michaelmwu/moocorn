# Moocorn Configuration
# MOOCORN_BACKEND_PORT=8888

# Frontend variables (VITE_ prefix required for client-side access)
# MOOCORN_FRONTEND_PORT=5173

# Default is http://localhost:8888
# VITE_MOOCORN_API_URL=http://localhost:8888

## LLM Configuration
# We default to an OpenAI compatible API, but open to using other APIs like Gemini!
# LLM_PROVIDER=ollama
# Override to point to the LLM provider
# LLM_BASE_URL=http://localhost:11434/v1
# Docker specific LLM_BASE_URL, as it needs special syntax to point to localhost
# DOCKER_LLM_BASE_URL=http://host.docker.internal:8080/v1
# Defaults
# LLM_MODEL=phi